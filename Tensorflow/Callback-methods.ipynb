{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d2992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7c031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e48ca",
   "metadata": {},
   "source": [
    "### 1] ModelCheckpoint\n",
    "\n",
    "#### Description:\n",
    "The `ModelCheckpoint` callback is used to **save the model or weights at specified intervals, typically at the end of an epoch**. **It is particularly useful for saving the best version of the model (based on validation performance) during training**.\n",
    "\n",
    "#### Use Case:\n",
    "- **Saving the Best Model**: When training a neural network, it is common to save the model that performs best on the validation set to avoid overfitting.\n",
    "- **Periodic Saving**: To periodically save the model during training in case of interruption, which allows resuming training from the last checkpoint.\n",
    "- **Tracking Progress**: To save models at different stages of training for later comparison.\n",
    "\n",
    "#### Syntax:\n",
    "```python\n",
    "tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    "    options=None,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "#### Parameters:\n",
    "- `filepath`: String, path where the model file will be saved. Can contain placeholders such as `{epoch}` and `{val_loss:.2f}`.\n",
    "- `monitor`: Quantity to be monitored. Default is `'val_loss'`.\n",
    "- `verbose`: Verbosity mode, 0 or 1.\n",
    "- `save_best_only`: If `True`, the latest best model according to the quantity monitored will not be overwritten.\n",
    "- `save_weights_only`: If `True`, then only the model's weights will be saved (`model.save_weights(filepath)`), else the full model is saved (`model.save(filepath)`).\n",
    "- `mode`: One of `{'auto', 'min', 'max'}`. If `save_best_only=True`, the decision to overwrite the current save file is made based on the maximization or minimization of the monitored quantity. For `val_acc`, this would be `max`, for `val_loss` this would be `min`, etc. In `auto` mode, the direction is inferred automatically from the name of the monitored quantity.\n",
    "- `save_freq`: `'epoch'` or integer. When using `'epoch'`, the callback saves the model after each epoch. When using an integer, the callback saves the model at end of this many batches.\n",
    "- `options`: Optional `tf.train.CheckpointOptions` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a85cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model=tf.keras.Sequential([\n",
    "    #input layer\n",
    "    tf.keras.layers.Dense(64,activation='relu',input_shape=(32,)),\n",
    "    #hidden layer\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    #ouput since it has classes from 0 to 9 totally 10 classes\n",
    "    tf.keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "#o/p class are integer label --> so using sparse categorrical cross entropy\n",
    "#o/p metrics for classificatio  --> accuracy / precision here we using accuracy\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb6b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy data\n",
    "\n",
    "#training set\n",
    "x_train=tf.random.normal((1000,32))\n",
    "y_train=tf.random.uniform((1000,),maxval=10,dtype=tf.int32)\n",
    "\n",
    "#testing set\n",
    "x_val=tf.random.normal((200,32))\n",
    "y_val=tf.random.uniform((200,),maxval=10,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127878d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.h5',  # File path to save the model\n",
    "    monitor='val_loss',# Quantity to monitor, e.g., validation loss\n",
    "    verbose=1 ,                 # Verbosity mode: 0 (silent), 1 (progress bar), or 2 (one line per epoch)\n",
    "    save_best_only=True,       # Save only the best model, not after every epoch\n",
    "    save_weights_only=False,   # Save the whole model (True to save only weights)\n",
    "    mode='min',                # Mode: 'min' because we want to minimize validation loss\n",
    "    save_freq='epoch',         # Save the model after every epoch\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "259d6c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 1.8488 - accuracy: 0.4167\n",
      "Epoch 1: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.8483 - accuracy: 0.4110 - val_loss: 2.5155 - val_accuracy: 0.1050\n",
      "Epoch 2/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 1.8113 - accuracy: 0.4317\n",
      "Epoch 2: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.8011 - accuracy: 0.4380 - val_loss: 2.5414 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 1.7446 - accuracy: 0.4601\n",
      "Epoch 3: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7502 - accuracy: 0.4530 - val_loss: 2.5700 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.7034 - accuracy: 0.4870\n",
      "Epoch 4: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7034 - accuracy: 0.4870 - val_loss: 2.5884 - val_accuracy: 0.0950\n",
      "Epoch 5/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 1.6470 - accuracy: 0.5054\n",
      "Epoch 5: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6496 - accuracy: 0.5040 - val_loss: 2.6277 - val_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 1.5879 - accuracy: 0.5323\n",
      "Epoch 6: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5976 - accuracy: 0.5300 - val_loss: 2.6494 - val_accuracy: 0.0850\n",
      "Epoch 7/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.5457 - accuracy: 0.5575\n",
      "Epoch 7: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5444 - accuracy: 0.5580 - val_loss: 2.6968 - val_accuracy: 0.0900\n",
      "Epoch 8/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 1.4989 - accuracy: 0.5573\n",
      "Epoch 8: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4978 - accuracy: 0.5570 - val_loss: 2.7134 - val_accuracy: 0.0800\n",
      "Epoch 9/10\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 1.4390 - accuracy: 0.5882\n",
      "Epoch 9: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4397 - accuracy: 0.5860 - val_loss: 2.7617 - val_accuracy: 0.0850\n",
      "Epoch 10/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 1.3769 - accuracy: 0.6073\n",
      "Epoch 10: val_loss did not improve from 2.36599\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3868 - accuracy: 0.6030 - val_loss: 2.7983 - val_accuracy: 0.0800\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=10,callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732b9ff",
   "metadata": {},
   "source": [
    "### 2] EarlyStopping\n",
    "\n",
    "#### Description:\n",
    "The `EarlyStopping` callback in Keras is **used to stop training when a monitored metric has stopped improving**. It helps to **prevent overfitting by halting the training process when the model performance on a validation set does not improve** for a specified number of epochs.\n",
    "\n",
    "#### Use Case:\n",
    "- **Preventing Overfitting**: Stops training when the model starts to overfit the training data and the performance on the validation set deteriorates.\n",
    "- **Resource Efficiency**: Saves computational resources by halting the training process early instead of running for a fixed number of epochs.\n",
    "- **Improving Model Generalization**: Helps in achieving better generalization by stopping at the right point before overfitting occurs.\n",
    "\n",
    "#### Syntax:\n",
    "```python\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0\n",
    ")\n",
    "```\n",
    "\n",
    "#### Parameters:\n",
    "- `monitor`: Quantity to be monitored. Default is `'val_loss'`.\n",
    "- `min_delta`: **Minimum change in the monitored quantity to qualify as an improvement**, i.e., an absolute change of less than `min_delta` will count as no improvement.\n",
    "- `patience`: Number of epochs with no improvement after which training will be stopped.\n",
    "- `verbose`: Verbosity mode, 0 or 1.\n",
    "- `mode`: One of `{'auto', 'min', 'max'}`. In `min` mode, training will stop when the `val_loss` monitored has stopped decreasing; in `max` mode it will stop when the `val_acc` monitored has stopped increasing; in `auto` mode, the direction is inferred automatically from the name of the monitored quantity.\n",
    "- `baseline`: Baseline value for the monitored quantity. Training will stop if the model doesn't show improvement over the baseline.**For example, if you know that a validation accuracy below 80% is not acceptable, you can set baseline=0.8**\n",
    "- `restore_best_weights`: Whether to restore model weights from the epoch with the best value of the monitored quantity. If `False`, the model weights obtained at the last step of training are used.\n",
    "- `start_from_epoch`: Number of epochs to wait before starting to monitor improvement."
   ]
  },
  {
   "cell_type": "raw",
   "id": "650e5b77",
   "metadata": {},
   "source": [
    "Using the same architecture which is used in above model checkpoint example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f7eb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',        # Monitoring validation loss\n",
    "    patience=3,                # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,                 # Verbosity mode\n",
    "    mode='min',                # Mode 'min' since we are monitoring loss\n",
    "    baseline=0.4,              # Training will stop if val_loss does not improve over 0.4\n",
    "    min_delta=0.01,            # Minimum change to qualify as an improvement\n",
    "    start_from_epoch=10,       # Start monitoring from the 10th epoch\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "863e82c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.8472 - accuracy: 0.8350 - val_loss: 3.2616 - val_accuracy: 0.1050\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8058 - accuracy: 0.8420 - val_loss: 3.3380 - val_accuracy: 0.0800\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.7622 - accuracy: 0.8630 - val_loss: 3.4014 - val_accuracy: 0.0950\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7245 - accuracy: 0.8740 - val_loss: 3.4583 - val_accuracy: 0.0950\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6807 - accuracy: 0.8940 - val_loss: 3.4841 - val_accuracy: 0.0900\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6438 - accuracy: 0.9050 - val_loss: 3.5692 - val_accuracy: 0.0950\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.9140 - val_loss: 3.6186 - val_accuracy: 0.1000\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5715 - accuracy: 0.9180 - val_loss: 3.6811 - val_accuracy: 0.0750\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5394 - accuracy: 0.9320 - val_loss: 3.7429 - val_accuracy: 0.0900\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5033 - accuracy: 0.9370 - val_loss: 3.7929 - val_accuracy: 0.0850\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4720 - accuracy: 0.9490 - val_loss: 3.8510 - val_accuracy: 0.1000\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4447 - accuracy: 0.9500 - val_loss: 3.9126 - val_accuracy: 0.0900\n",
      "Epoch 13/500\n",
      "21/32 [==================>...........] - ETA: 0s - loss: 0.3981 - accuracy: 0.9673Restoring model weights from the end of the best epoch: 11.\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4205 - accuracy: 0.9600 - val_loss: 3.9514 - val_accuracy: 0.0850\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=500,callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f44bfe",
   "metadata": {},
   "source": [
    "### 3] ReduceLROnPlateau\n",
    "\n",
    "The `ReduceLROnPlateau` callback in Keras is **used to reduce the learning rate when a monitored metric has stopped improving**. This is particularly **useful for fine-tuning the learning process**, ensuring that the model can converge to a better solution without getting stuck at a suboptimal learning rate.\n",
    "\n",
    "\n",
    "#### Syntax\n",
    "\n",
    "```python\n",
    "tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0\n",
    ")\n",
    "```\n",
    "\n",
    "- **Key Parameters**:\n",
    "  - `monitor`: The metric to be monitored (e.g., `val_loss`).\n",
    "  - `factor`: The factor by which the learning rate will be reduced (new_lr = lr * factor).\n",
    "  - `patience`: Number of epochs with no improvement after which the learning rate will be reduced.\n",
    "  - `verbose`: Verbosity mode (0 or 1).\n",
    "  - `mode`: One of `{'auto', 'min', 'max'}`. In `min` mode, the learning rate will be reduced when the quantity monitored has stopped decreasing; in `max` mode, it will be reduced when the quantity monitored has stopped increasing.\n",
    "  - `min_delta`: Threshold for measuring the new optimum; to only focus on significant changes.\n",
    "  - `cooldown`: Number of epochs to wait before resuming normal operation after the learning rate has been reduced.\n",
    "  - `min_lr`: Lower bound on the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c1e441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    #input layer\n",
    "    tf.keras.layers.Dense(64,activation='relu',input_shape=(32,)),\n",
    "    #hidden layer\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    #ouput\n",
    "    tf.keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45649b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy data\n",
    "\n",
    "#train\n",
    "x_train=tf.random.normal((1000,32))\n",
    "y_train=tf.random.uniform((1000,),maxval=10,dtype=tf.int32)\n",
    "\n",
    "#validation dataset\n",
    "x_val=tf.random.normal((200,32))\n",
    "y_val=tf.random.uniform((200,),maxval=10,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f5ca1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau callback\n",
    "reduce_lr_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',    # Monitoring validation loss\n",
    "    factor=0.1,            # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "    patience=5,            # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    verbose=1,             # Verbosity mode\n",
    "    mode='min',            # Mode 'min' because we want to minimize validation loss\n",
    "    min_delta=0.001,       # Threshold for measuring the new optimum\n",
    "    cooldown=2,            # Number of epochs to wait before resuming normal operation after LR is reduced\n",
    "    min_lr=0.00001         # Lower bound on the learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4f8d585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/32 [==============================] - 2s 21ms/step - loss: 2.3466 - accuracy: 0.0900 - val_loss: 2.3055 - val_accuracy: 0.1100 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2568 - accuracy: 0.1540 - val_loss: 2.3162 - val_accuracy: 0.1250 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2011 - accuracy: 0.1870 - val_loss: 2.3349 - val_accuracy: 0.1000 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1513 - accuracy: 0.2430 - val_loss: 2.3512 - val_accuracy: 0.1050 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1092 - accuracy: 0.2750 - val_loss: 2.3664 - val_accuracy: 0.1050 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "31/32 [============================>.] - ETA: 0s - loss: 2.0595 - accuracy: 0.2974\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0605 - accuracy: 0.2950 - val_loss: 2.3889 - val_accuracy: 0.0950 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0076 - accuracy: 0.3290 - val_loss: 2.3911 - val_accuracy: 0.0950 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0018 - accuracy: 0.3360 - val_loss: 2.3937 - val_accuracy: 0.0950 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9967 - accuracy: 0.3370 - val_loss: 2.3956 - val_accuracy: 0.1000 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9918 - accuracy: 0.3430 - val_loss: 2.3981 - val_accuracy: 0.1100 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9867 - accuracy: 0.3400 - val_loss: 2.4006 - val_accuracy: 0.0950 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.9821 - accuracy: 0.3438\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9817 - accuracy: 0.3440 - val_loss: 2.4027 - val_accuracy: 0.0950 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9762 - accuracy: 0.3520 - val_loss: 2.4030 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9757 - accuracy: 0.3520 - val_loss: 2.4033 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9752 - accuracy: 0.3530 - val_loss: 2.4035 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9747 - accuracy: 0.3520 - val_loss: 2.4037 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9743 - accuracy: 0.3520 - val_loss: 2.4040 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 18/30\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 1.9797 - accuracy: 0.3502\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9737 - accuracy: 0.3520 - val_loss: 2.4042 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9733 - accuracy: 0.3530 - val_loss: 2.4044 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9728 - accuracy: 0.3530 - val_loss: 2.4046 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9724 - accuracy: 0.3520 - val_loss: 2.4049 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9718 - accuracy: 0.3520 - val_loss: 2.4050 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9714 - accuracy: 0.3540 - val_loss: 2.4053 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9709 - accuracy: 0.3520 - val_loss: 2.4055 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9705 - accuracy: 0.3530 - val_loss: 2.4058 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9700 - accuracy: 0.3550 - val_loss: 2.4060 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9695 - accuracy: 0.3560 - val_loss: 2.4063 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9691 - accuracy: 0.3540 - val_loss: 2.4064 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9686 - accuracy: 0.3540 - val_loss: 2.4069 - val_accuracy: 0.0950 - lr: 1.0000e-05\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9681 - accuracy: 0.3560 - val_loss: 2.4071 - val_accuracy: 0.0950 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=30,callbacks=[reduce_lr_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370ff1f",
   "metadata": {},
   "source": [
    "### 4] CSV logger\n",
    "\n",
    "\n",
    "- **Purpose**: To log the training metrics (loss and metrics) to a CSV file after each epoch during training.\n",
    "- **Use Case**: It helps in tracking the training progress, analyzing the trends of loss and metrics over epochs, and comparing different training runs.\n",
    "\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- Enables easy tracking and comparison of training metrics across epochs.\n",
    "- Facilitates visual analysis and debugging of model training.\n",
    "\n",
    "The CSVLogger is a simple yet effective tool for managing and reviewing model training progress in TensorFlow/Keras projects."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fff9f783",
   "metadata": {},
   "source": [
    "Using the same  model architecture which is used above 'ReduceLROnPlateu' example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fe6e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4709948f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9677 - accuracy: 0.3560 - val_loss: 2.4073 - val_accuracy: 0.0950\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9672 - accuracy: 0.3570 - val_loss: 2.4074 - val_accuracy: 0.0950\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9667 - accuracy: 0.3550 - val_loss: 2.4077 - val_accuracy: 0.0950\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9663 - accuracy: 0.3570 - val_loss: 2.4080 - val_accuracy: 0.0900\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9658 - accuracy: 0.3580 - val_loss: 2.4082 - val_accuracy: 0.0900\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9654 - accuracy: 0.3600 - val_loss: 2.4084 - val_accuracy: 0.0900\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9649 - accuracy: 0.3600 - val_loss: 2.4087 - val_accuracy: 0.0900\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9644 - accuracy: 0.3620 - val_loss: 2.4091 - val_accuracy: 0.0900\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9640 - accuracy: 0.3610 - val_loss: 2.4093 - val_accuracy: 0.0900\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9635 - accuracy: 0.3610 - val_loss: 2.4094 - val_accuracy: 0.0900\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=10,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e7067ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a335e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the stored log file\n",
    "log=pd.read_csv('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d37173fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.356</td>\n",
       "      <td>1.967657</td>\n",
       "      <td>0.095</td>\n",
       "      <td>2.407253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.357</td>\n",
       "      <td>1.967200</td>\n",
       "      <td>0.095</td>\n",
       "      <td>2.407428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.355</td>\n",
       "      <td>1.966738</td>\n",
       "      <td>0.095</td>\n",
       "      <td>2.407713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.357</td>\n",
       "      <td>1.966263</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.408009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.358</td>\n",
       "      <td>1.965820</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.408202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.360</td>\n",
       "      <td>1.965369</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.408405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.360</td>\n",
       "      <td>1.964866</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.408714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1.964439</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.409068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.361</td>\n",
       "      <td>1.963970</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.409299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.361</td>\n",
       "      <td>1.963524</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2.409408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  accuracy      loss  val_accuracy  val_loss\n",
       "0      0     0.356  1.967657         0.095  2.407253\n",
       "1      1     0.357  1.967200         0.095  2.407428\n",
       "2      2     0.355  1.966738         0.095  2.407713\n",
       "3      3     0.357  1.966263         0.090  2.408009\n",
       "4      4     0.358  1.965820         0.090  2.408202\n",
       "5      5     0.360  1.965369         0.090  2.408405\n",
       "6      6     0.360  1.964866         0.090  2.408714\n",
       "7      7     0.362  1.964439         0.090  2.409068\n",
       "8      8     0.361  1.963970         0.090  2.409299\n",
       "9      9     0.361  1.963524         0.090  2.409408"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b66ae",
   "metadata": {},
   "source": [
    "### 5] TerminateOnNaN\n",
    "\n",
    "\n",
    "- **Purpose**: To terminate the training process if the loss becomes NaN during training.\n",
    "- **Use Case**: This callback is essential for ensuring the stability and reliability of training, especially when dealing with large datasets or complex models where numerical instability might occur.\n",
    "\n",
    "##### Example Scenario\n",
    "\n",
    "Suppose during training, **the loss function starts producing NaN values due to some numerical instability in the model's computations. Without the TerminateOnNaN callback, the training process would continue, potentially leading to inaccurate model updates and wasted computational resources.** By using this callback, TensorFlow/Keras can automatically halt the training process upon detecting such issues, allowing you to investigate and address the underlying causes.\n",
    "\n",
    "##### Benefits\n",
    "\n",
    "- Ensures training stability by stopping on encountering NaN values in the loss.\n",
    "- Helps in debugging model training issues related to numerical instability.\n",
    "- Prevents wasted computational resources and time by halting training early when issues arise.\n",
    "\n",
    "In summary, the TerminateOnNaN callback is a critical tool for maintaining the integrity and reliability of model training in TensorFlow/Keras, ensuring that the training process halts promptly upon detecting NaN values in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4af04fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TerminateOnNaN callback\n",
    "terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f9af59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9631 - accuracy: 0.3630 - val_loss: 2.4097 - val_accuracy: 0.0900\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9626 - accuracy: 0.3630 - val_loss: 2.4099 - val_accuracy: 0.0900\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9621 - accuracy: 0.3640 - val_loss: 2.4102 - val_accuracy: 0.0900\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9617 - accuracy: 0.3650 - val_loss: 2.4103 - val_accuracy: 0.0900\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9612 - accuracy: 0.3660 - val_loss: 2.4105 - val_accuracy: 0.0900\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9608 - accuracy: 0.3660 - val_loss: 2.4107 - val_accuracy: 0.0850\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9603 - accuracy: 0.3650 - val_loss: 2.4108 - val_accuracy: 0.0850\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.9599 - accuracy: 0.3650 - val_loss: 2.4111 - val_accuracy: 0.0900\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9594 - accuracy: 0.3660 - val_loss: 2.4112 - val_accuracy: 0.0850\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9589 - accuracy: 0.3650 - val_loss: 2.4116 - val_accuracy: 0.0850\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.9585 - accuracy: 0.3640 - val_loss: 2.4119 - val_accuracy: 0.0850\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9580 - accuracy: 0.3670 - val_loss: 2.4119 - val_accuracy: 0.0850\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9576 - accuracy: 0.3680 - val_loss: 2.4121 - val_accuracy: 0.0850\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9571 - accuracy: 0.3680 - val_loss: 2.4123 - val_accuracy: 0.0850\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9566 - accuracy: 0.3690 - val_loss: 2.4126 - val_accuracy: 0.0850\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9562 - accuracy: 0.3700 - val_loss: 2.4129 - val_accuracy: 0.0850\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9557 - accuracy: 0.3700 - val_loss: 2.4131 - val_accuracy: 0.0850\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9553 - accuracy: 0.3710 - val_loss: 2.4134 - val_accuracy: 0.0850\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9548 - accuracy: 0.3700 - val_loss: 2.4137 - val_accuracy: 0.0850\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9544 - accuracy: 0.3710 - val_loss: 2.4139 - val_accuracy: 0.0850\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9539 - accuracy: 0.3690 - val_loss: 2.4142 - val_accuracy: 0.0850\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.9534 - accuracy: 0.3700 - val_loss: 2.4144 - val_accuracy: 0.0850\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.9530 - accuracy: 0.3720 - val_loss: 2.4146 - val_accuracy: 0.0850\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9525 - accuracy: 0.3700 - val_loss: 2.4149 - val_accuracy: 0.0850\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9521 - accuracy: 0.3720 - val_loss: 2.4151 - val_accuracy: 0.0850\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9516 - accuracy: 0.3720 - val_loss: 2.4153 - val_accuracy: 0.0850\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9512 - accuracy: 0.3720 - val_loss: 2.4156 - val_accuracy: 0.0850\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9507 - accuracy: 0.3710 - val_loss: 2.4157 - val_accuracy: 0.0850\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.9502 - accuracy: 0.3730 - val_loss: 2.4161 - val_accuracy: 0.0850\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9498 - accuracy: 0.3750 - val_loss: 2.4163 - val_accuracy: 0.0850\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9493 - accuracy: 0.3730 - val_loss: 2.4166 - val_accuracy: 0.0850\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9489 - accuracy: 0.3740 - val_loss: 2.4168 - val_accuracy: 0.0850\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9484 - accuracy: 0.3740 - val_loss: 2.4172 - val_accuracy: 0.0850\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9480 - accuracy: 0.3740 - val_loss: 2.4175 - val_accuracy: 0.0850\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.9475 - accuracy: 0.3730 - val_loss: 2.4177 - val_accuracy: 0.0850\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9471 - accuracy: 0.3730 - val_loss: 2.4180 - val_accuracy: 0.0850\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9466 - accuracy: 0.3740 - val_loss: 2.4183 - val_accuracy: 0.0850\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9462 - accuracy: 0.3730 - val_loss: 2.4185 - val_accuracy: 0.0850\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9457 - accuracy: 0.3730 - val_loss: 2.4186 - val_accuracy: 0.0850\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.9453 - accuracy: 0.3750 - val_loss: 2.4189 - val_accuracy: 0.0850\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=40,callbacks=[terminate_on_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f782cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since no nan occur so it runs for all epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a3293",
   "metadata": {},
   "source": [
    "### 6] Learning Rate Scheduler\n",
    "\n",
    "A learning rate scheduler in TensorFlow/Keras is a callback used to adjust the learning rate during training. Adjusting the learning rate can help improve convergence and model performance.\n",
    "\n",
    "#### Description\n",
    "\n",
    "- **Purpose**: To dynamically change the learning rate based on the epoch or other criteria.\n",
    "- **Use Case**: Often used in training deep learning models to start with a higher learning rate for faster convergence and gradually reduce it to fine-tune the model.\n",
    "\n",
    "#### Types of Learning Rate Schedulers\n",
    "\n",
    "1. **Exponential Decay**: Reduces the learning rate by a factor of the decay rate every certain number of epochs.\n",
    "2. **Step Decay**: Reduces the learning rate by a factor every few epochs.\n",
    "3. **Polynomial Decay**: Reduces the learning rate following a polynomial function.\n",
    "4. **Inverse Time Decay**: Reduces the learning rate as a function of the inverse of time.\n",
    "\n",
    "\n",
    "\n",
    "#### Explanation of Parameters\n",
    "\n",
    "- **`initial_learning_rate`**: The starting learning rate.\n",
    "- **`decay_steps`**: The number of steps after which the learning rate decays.\n",
    "       **Example: If decay_steps = 1000, it means that the learning rate will remain constant for the first 1000 epochs.**\n",
    "- **`decay_rate`**: The factor by which the learning rate decays.\n",
    "       **If decay_rate = 0.96, it means that after every decay_steps, the learning rate will be multiplied by 0.96.**\n",
    "       \n",
    "- **`staircase`**: \n",
    "                  **When staircase=True:** The learning rate decreases in discrete steps after every decay_steps. This means that       the learning rate remains constant until the end of each decay_steps interval, and then it drops abruptly.\n",
    "\n",
    "\n",
    "                  **When staircase=False (default behavior):** The learning rate decreases smoothly and continuously with every         epoch, according to the exponential decay formula specified.\n",
    "- **`end_learning_rate`**: The learning rate after all decay steps are completed.\n",
    "- **`power`**: The power of the polynomial for polynomial decay.\n",
    "\n",
    "#### Use Case\n",
    "\n",
    "- **Exponential Decay**: When you want a smooth decay of learning rate over time.\n",
    "- **Step Decay**: When you want to reduce the learning rate at specific intervals (steps).\n",
    "- **Polynomial Decay**: When you want a custom decay rate following a polynomial function.\n",
    "- **Inverse Time Decay**: When you want the learning rate to decay inversely with time.\n",
    "\n",
    "These scheduling strategies help in adjusting the learning rate dynamically, improving the model's performance and convergence during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5d9c2",
   "metadata": {},
   "source": [
    "#### Exponential decay - eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76397e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 25ms/step - loss: 2.3745 - accuracy: 0.1010 - val_loss: 2.3192 - val_accuracy: 0.0850\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2791 - accuracy: 0.1500 - val_loss: 2.3022 - val_accuracy: 0.0800\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2281 - accuracy: 0.1760 - val_loss: 2.3172 - val_accuracy: 0.1150\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1808 - accuracy: 0.2200 - val_loss: 2.3300 - val_accuracy: 0.1050\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.1416 - accuracy: 0.2500 - val_loss: 2.3636 - val_accuracy: 0.1000\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.1024 - accuracy: 0.2650 - val_loss: 2.3554 - val_accuracy: 0.1000\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.0610 - accuracy: 0.2760 - val_loss: 2.3559 - val_accuracy: 0.0950\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0188 - accuracy: 0.3090 - val_loss: 2.3595 - val_accuracy: 0.0850\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9757 - accuracy: 0.3370 - val_loss: 2.3906 - val_accuracy: 0.1000\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.9304 - accuracy: 0.3520 - val_loss: 2.4507 - val_accuracy: 0.1000\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.8855 - accuracy: 0.3720 - val_loss: 2.4337 - val_accuracy: 0.1250\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.8368 - accuracy: 0.3880 - val_loss: 2.4309 - val_accuracy: 0.1150\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7837 - accuracy: 0.4160 - val_loss: 2.4502 - val_accuracy: 0.1100\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.7336 - accuracy: 0.4130 - val_loss: 2.5304 - val_accuracy: 0.1300\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6794 - accuracy: 0.4720 - val_loss: 2.5670 - val_accuracy: 0.1350\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 1.6241 - accuracy: 0.4750 - val_loss: 2.6028 - val_accuracy: 0.1400\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5646 - accuracy: 0.4900 - val_loss: 2.6326 - val_accuracy: 0.1400\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.5119 - accuracy: 0.5240 - val_loss: 2.7072 - val_accuracy: 0.1050\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4496 - accuracy: 0.5410 - val_loss: 2.7085 - val_accuracy: 0.1050\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3852 - accuracy: 0.5660 - val_loss: 2.8329 - val_accuracy: 0.1350\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.5670 - val_loss: 2.8193 - val_accuracy: 0.1200\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.2720 - accuracy: 0.6140 - val_loss: 2.9346 - val_accuracy: 0.1350\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2140 - accuracy: 0.6390 - val_loss: 2.9076 - val_accuracy: 0.1200\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.1552 - accuracy: 0.6560 - val_loss: 3.0795 - val_accuracy: 0.1300\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0878 - accuracy: 0.6770 - val_loss: 3.1271 - val_accuracy: 0.1250\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0303 - accuracy: 0.7050 - val_loss: 3.1766 - val_accuracy: 0.1300\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9833 - accuracy: 0.7220 - val_loss: 3.3970 - val_accuracy: 0.1000\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9186 - accuracy: 0.7400 - val_loss: 3.4077 - val_accuracy: 0.1250\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8656 - accuracy: 0.7660 - val_loss: 3.5451 - val_accuracy: 0.1150\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8010 - accuracy: 0.7930 - val_loss: 3.5969 - val_accuracy: 0.1150\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7337 - accuracy: 0.8160 - val_loss: 3.6756 - val_accuracy: 0.1550\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6810 - accuracy: 0.8380 - val_loss: 3.8244 - val_accuracy: 0.1200\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6254 - accuracy: 0.8520 - val_loss: 3.9131 - val_accuracy: 0.1100\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5794 - accuracy: 0.8790 - val_loss: 4.0712 - val_accuracy: 0.1000\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5230 - accuracy: 0.8990 - val_loss: 4.1195 - val_accuracy: 0.1150\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4653 - accuracy: 0.9210 - val_loss: 4.2148 - val_accuracy: 0.1400\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4229 - accuracy: 0.9400 - val_loss: 4.4951 - val_accuracy: 0.1100\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4039 - accuracy: 0.9460 - val_loss: 4.5406 - val_accuracy: 0.0950\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3442 - accuracy: 0.9610 - val_loss: 4.6769 - val_accuracy: 0.1100\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3076 - accuracy: 0.9730 - val_loss: 4.8366 - val_accuracy: 0.1150\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2818 - accuracy: 0.9770 - val_loss: 4.9641 - val_accuracy: 0.1000\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2585 - accuracy: 0.9790 - val_loss: 4.9878 - val_accuracy: 0.1050\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2222 - accuracy: 0.9860 - val_loss: 5.1911 - val_accuracy: 0.1150\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1962 - accuracy: 0.9930 - val_loss: 5.2139 - val_accuracy: 0.1150\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1752 - accuracy: 0.9960 - val_loss: 5.3620 - val_accuracy: 0.0950\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1541 - accuracy: 0.9980 - val_loss: 5.4377 - val_accuracy: 0.0900\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1402 - accuracy: 0.9990 - val_loss: 5.5525 - val_accuracy: 0.1050\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1249 - accuracy: 0.9980 - val_loss: 5.7930 - val_accuracy: 0.1050\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1258 - accuracy: 0.9980 - val_loss: 5.8234 - val_accuracy: 0.0950\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1062 - accuracy: 0.9990 - val_loss: 5.8391 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# Sample model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "x_train = tf.random.normal((1000, 32))\n",
    "y_train = tf.random.uniform((1000,), maxval=10, dtype=tf.int32)\n",
    "x_val = tf.random.normal((200, 32))\n",
    "y_val = tf.random.uniform((200,), maxval=10, dtype=tf.int32)\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a1294",
   "metadata": {},
   "source": [
    "#### Step decay - eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b8549fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 3s 22ms/step - loss: 2.4287 - accuracy: 0.0970 - val_loss: 2.3499 - val_accuracy: 0.1100 - lr: 0.1000\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3199 - accuracy: 0.1000 - val_loss: 2.3224 - val_accuracy: 0.1150 - lr: 0.1000\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3085 - accuracy: 0.1150 - val_loss: 2.3095 - val_accuracy: 0.0650 - lr: 0.1000\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3051 - accuracy: 0.1180 - val_loss: 2.3652 - val_accuracy: 0.0650 - lr: 0.1000\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3196 - accuracy: 0.0910 - val_loss: 2.3418 - val_accuracy: 0.0650 - lr: 0.1000\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3079 - accuracy: 0.0870 - val_loss: 2.3328 - val_accuracy: 0.1150 - lr: 0.1000\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3042 - accuracy: 0.1210 - val_loss: 2.3285 - val_accuracy: 0.0650 - lr: 0.1000\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3082 - accuracy: 0.1210 - val_loss: 2.3375 - val_accuracy: 0.1150 - lr: 0.1000\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3031 - accuracy: 0.1200 - val_loss: 2.3322 - val_accuracy: 0.1150 - lr: 0.1000\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3095 - accuracy: 0.1070 - val_loss: 2.3341 - val_accuracy: 0.0650 - lr: 0.1000\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3020 - accuracy: 0.1120 - val_loss: 2.3190 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3013 - accuracy: 0.1030 - val_loss: 2.3272 - val_accuracy: 0.0650 - lr: 0.0500\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2982 - accuracy: 0.1100 - val_loss: 2.3152 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3032 - accuracy: 0.1130 - val_loss: 2.3201 - val_accuracy: 0.0650 - lr: 0.0500\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3012 - accuracy: 0.1110 - val_loss: 2.3225 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2987 - accuracy: 0.1070 - val_loss: 2.3152 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3025 - accuracy: 0.1080 - val_loss: 2.3192 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2998 - accuracy: 0.1140 - val_loss: 2.3182 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3002 - accuracy: 0.1220 - val_loss: 2.3197 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3002 - accuracy: 0.1050 - val_loss: 2.3220 - val_accuracy: 0.1150 - lr: 0.0500\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2969 - accuracy: 0.1220 - val_loss: 2.3184 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2966 - accuracy: 0.1220 - val_loss: 2.3210 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2965 - accuracy: 0.1220 - val_loss: 2.3179 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2988 - accuracy: 0.1220 - val_loss: 2.3207 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2970 - accuracy: 0.1220 - val_loss: 2.3250 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2962 - accuracy: 0.1100 - val_loss: 2.3224 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2969 - accuracy: 0.1220 - val_loss: 2.3217 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2972 - accuracy: 0.1220 - val_loss: 2.3239 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2974 - accuracy: 0.1110 - val_loss: 2.3244 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2965 - accuracy: 0.1070 - val_loss: 2.3201 - val_accuracy: 0.1150 - lr: 0.0250\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.2955 - accuracy: 0.1220 - val_loss: 2.3168 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2950 - accuracy: 0.1220 - val_loss: 2.3227 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2946 - accuracy: 0.1220 - val_loss: 2.3226 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2955 - accuracy: 0.1180 - val_loss: 2.3253 - val_accuracy: 0.0650 - lr: 0.0125\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2956 - accuracy: 0.1100 - val_loss: 2.3210 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2946 - accuracy: 0.1220 - val_loss: 2.3235 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2946 - accuracy: 0.1220 - val_loss: 2.3218 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2953 - accuracy: 0.1220 - val_loss: 2.3221 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2945 - accuracy: 0.1220 - val_loss: 2.3225 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2950 - accuracy: 0.1220 - val_loss: 2.3230 - val_accuracy: 0.1150 - lr: 0.0125\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2940 - accuracy: 0.1220 - val_loss: 2.3229 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2942 - accuracy: 0.1220 - val_loss: 2.3256 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2937 - accuracy: 0.1220 - val_loss: 2.3231 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2940 - accuracy: 0.1220 - val_loss: 2.3215 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2939 - accuracy: 0.1220 - val_loss: 2.3224 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2942 - accuracy: 0.1220 - val_loss: 2.3228 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.2940 - accuracy: 0.1220 - val_loss: 2.3218 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.2939 - accuracy: 0.1220 - val_loss: 2.3216 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.2939 - accuracy: 0.1220 - val_loss: 2.3219 - val_accuracy: 0.1150 - lr: 0.0063\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2943 - accuracy: 0.1220 - val_loss: 2.3227 - val_accuracy: 0.1150 - lr: 0.0063\n"
     ]
    }
   ],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lr = 0.1\n",
    "    drop = 0.5 # Factor by which the learning rate is reduced\n",
    "    epochs_drop = 10 #the learning rate remains constant at initial_lr for 10 epochs as mentioned here\n",
    "    lr = initial_lr * (drop ** ((epoch) // epochs_drop))\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "\n",
    "# Sample model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "x_train = tf.random.normal((1000, 32))\n",
    "y_train = tf.random.uniform((1000,), maxval=10, dtype=tf.int32)\n",
    "x_val = tf.random.normal((200, 32))\n",
    "y_val = tf.random.uniform((200,), maxval=10, dtype=tf.int32)\n",
    "\n",
    "# Training with Step Decay\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae729da",
   "metadata": {},
   "source": [
    "#### Polynomial decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44e78780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 21ms/step - loss: 2.3607 - accuracy: 0.1140 - val_loss: 2.3280 - val_accuracy: 0.1050\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2712 - accuracy: 0.1440 - val_loss: 2.3583 - val_accuracy: 0.0850\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.2238 - accuracy: 0.1730 - val_loss: 2.3280 - val_accuracy: 0.1150\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1798 - accuracy: 0.2010 - val_loss: 2.3347 - val_accuracy: 0.1400\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1385 - accuracy: 0.2380 - val_loss: 2.3896 - val_accuracy: 0.0850\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0936 - accuracy: 0.2650 - val_loss: 2.3600 - val_accuracy: 0.0850\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0509 - accuracy: 0.2880 - val_loss: 2.3630 - val_accuracy: 0.0950\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.0039 - accuracy: 0.3180 - val_loss: 2.4036 - val_accuracy: 0.0900\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9540 - accuracy: 0.3360 - val_loss: 2.4371 - val_accuracy: 0.0800\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9050 - accuracy: 0.3570 - val_loss: 2.4571 - val_accuracy: 0.0750\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.8523 - accuracy: 0.3840 - val_loss: 2.4654 - val_accuracy: 0.0950\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.8026 - accuracy: 0.4030 - val_loss: 2.5457 - val_accuracy: 0.0650\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.7442 - accuracy: 0.4200 - val_loss: 2.5872 - val_accuracy: 0.0750\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6823 - accuracy: 0.4480 - val_loss: 2.5991 - val_accuracy: 0.1000\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6322 - accuracy: 0.4640 - val_loss: 2.6032 - val_accuracy: 0.1050\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5589 - accuracy: 0.4950 - val_loss: 2.6733 - val_accuracy: 0.1000\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5024 - accuracy: 0.5120 - val_loss: 2.8026 - val_accuracy: 0.1050\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4458 - accuracy: 0.5390 - val_loss: 2.7985 - val_accuracy: 0.0900\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.3763 - accuracy: 0.5520 - val_loss: 2.8346 - val_accuracy: 0.1100\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.3079 - accuracy: 0.5890 - val_loss: 2.9029 - val_accuracy: 0.1100\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2539 - accuracy: 0.6220 - val_loss: 2.9530 - val_accuracy: 0.1100\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.1875 - accuracy: 0.6470 - val_loss: 3.0673 - val_accuracy: 0.0900\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.1277 - accuracy: 0.6470 - val_loss: 3.1358 - val_accuracy: 0.0750\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0579 - accuracy: 0.7060 - val_loss: 3.2930 - val_accuracy: 0.1250\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9972 - accuracy: 0.6980 - val_loss: 3.2674 - val_accuracy: 0.1200\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9445 - accuracy: 0.7300 - val_loss: 3.3544 - val_accuracy: 0.1050\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8717 - accuracy: 0.7620 - val_loss: 3.3764 - val_accuracy: 0.1000\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8165 - accuracy: 0.7760 - val_loss: 3.6904 - val_accuracy: 0.1300\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7667 - accuracy: 0.8060 - val_loss: 3.7355 - val_accuracy: 0.1100\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.8360 - val_loss: 3.8025 - val_accuracy: 0.1250\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6298 - accuracy: 0.8580 - val_loss: 3.9652 - val_accuracy: 0.1100\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5660 - accuracy: 0.8720 - val_loss: 3.9907 - val_accuracy: 0.1250\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.9040 - val_loss: 4.0640 - val_accuracy: 0.1000\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.9250 - val_loss: 4.3219 - val_accuracy: 0.0900\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.9370 - val_loss: 4.3413 - val_accuracy: 0.1050\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3739 - accuracy: 0.9510 - val_loss: 4.3611 - val_accuracy: 0.1200\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.9570 - val_loss: 4.6821 - val_accuracy: 0.1150\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.9710 - val_loss: 4.7180 - val_accuracy: 0.1250\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2643 - accuracy: 0.9810 - val_loss: 4.7400 - val_accuracy: 0.1100\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2341 - accuracy: 0.9860 - val_loss: 4.9288 - val_accuracy: 0.0950\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2097 - accuracy: 0.9910 - val_loss: 5.1770 - val_accuracy: 0.1050\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1806 - accuracy: 0.9950 - val_loss: 5.1544 - val_accuracy: 0.1200\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9990 - val_loss: 5.2635 - val_accuracy: 0.1350\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 1.0000 - val_loss: 5.3012 - val_accuracy: 0.1000\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 5.4471 - val_accuracy: 0.1000\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1172 - accuracy: 0.9990 - val_loss: 5.5618 - val_accuracy: 0.1300\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 5.7069 - val_accuracy: 0.1200\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 5.7518 - val_accuracy: 0.1300\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 5.8062 - val_accuracy: 0.1200\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 5.8856 - val_accuracy: 0.1200\n"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    end_learning_rate=0.01,\n",
    "    power=1.0\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# Sample model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "x_train = tf.random.normal((1000, 32))\n",
    "y_train = tf.random.uniform((1000,), maxval=10, dtype=tf.int32)\n",
    "x_val = tf.random.normal((200, 32))\n",
    "y_val = tf.random.uniform((200,), maxval=10, dtype=tf.int32)\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea7fb4",
   "metadata": {},
   "source": [
    "#### Inverse time decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e7c4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 28ms/step - loss: 2.3939 - accuracy: 0.0900 - val_loss: 2.3562 - val_accuracy: 0.0700\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3629 - accuracy: 0.0980 - val_loss: 2.3502 - val_accuracy: 0.0800\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3560 - accuracy: 0.1020 - val_loss: 2.3470 - val_accuracy: 0.0850\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3519 - accuracy: 0.1040 - val_loss: 2.3450 - val_accuracy: 0.0850\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3493 - accuracy: 0.1090 - val_loss: 2.3437 - val_accuracy: 0.0800\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3472 - accuracy: 0.1100 - val_loss: 2.3427 - val_accuracy: 0.0800\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3455 - accuracy: 0.1110 - val_loss: 2.3418 - val_accuracy: 0.0800\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3441 - accuracy: 0.1090 - val_loss: 2.3410 - val_accuracy: 0.0750\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.3429 - accuracy: 0.1100 - val_loss: 2.3404 - val_accuracy: 0.0800\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3419 - accuracy: 0.1110 - val_loss: 2.3398 - val_accuracy: 0.0800\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3410 - accuracy: 0.1100 - val_loss: 2.3394 - val_accuracy: 0.0850\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3402 - accuracy: 0.1100 - val_loss: 2.3390 - val_accuracy: 0.0850\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3394 - accuracy: 0.1120 - val_loss: 2.3386 - val_accuracy: 0.0900\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3388 - accuracy: 0.1120 - val_loss: 2.3383 - val_accuracy: 0.0900\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3382 - accuracy: 0.1120 - val_loss: 2.3380 - val_accuracy: 0.0900\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3376 - accuracy: 0.1130 - val_loss: 2.3377 - val_accuracy: 0.0900\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3371 - accuracy: 0.1130 - val_loss: 2.3375 - val_accuracy: 0.0900\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3366 - accuracy: 0.1130 - val_loss: 2.3373 - val_accuracy: 0.0850\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3361 - accuracy: 0.1140 - val_loss: 2.3370 - val_accuracy: 0.0900\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3357 - accuracy: 0.1140 - val_loss: 2.3368 - val_accuracy: 0.0900\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3353 - accuracy: 0.1150 - val_loss: 2.3366 - val_accuracy: 0.0900\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3349 - accuracy: 0.1140 - val_loss: 2.3365 - val_accuracy: 0.0900\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3346 - accuracy: 0.1160 - val_loss: 2.3363 - val_accuracy: 0.0900\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3342 - accuracy: 0.1160 - val_loss: 2.3362 - val_accuracy: 0.0900\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3339 - accuracy: 0.1160 - val_loss: 2.3360 - val_accuracy: 0.0900\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3335 - accuracy: 0.1150 - val_loss: 2.3359 - val_accuracy: 0.0900\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3333 - accuracy: 0.1150 - val_loss: 2.3358 - val_accuracy: 0.0900\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3330 - accuracy: 0.1150 - val_loss: 2.3356 - val_accuracy: 0.0900\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3327 - accuracy: 0.1150 - val_loss: 2.3355 - val_accuracy: 0.0900\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.3324 - accuracy: 0.1150 - val_loss: 2.3354 - val_accuracy: 0.0900\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 2.3322 - accuracy: 0.1160 - val_loss: 2.3353 - val_accuracy: 0.0850\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3319 - accuracy: 0.1160 - val_loss: 2.3352 - val_accuracy: 0.0900\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3317 - accuracy: 0.1160 - val_loss: 2.3351 - val_accuracy: 0.0850\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3315 - accuracy: 0.1150 - val_loss: 2.3350 - val_accuracy: 0.0850\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3312 - accuracy: 0.1160 - val_loss: 2.3349 - val_accuracy: 0.0850\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.3310 - accuracy: 0.1160 - val_loss: 2.3348 - val_accuracy: 0.0850\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 2.3308 - accuracy: 0.1170 - val_loss: 2.3347 - val_accuracy: 0.0900\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.3306 - accuracy: 0.1170 - val_loss: 2.3346 - val_accuracy: 0.0850\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3304 - accuracy: 0.1150 - val_loss: 2.3345 - val_accuracy: 0.0850\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3302 - accuracy: 0.1150 - val_loss: 2.3344 - val_accuracy: 0.0850\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3300 - accuracy: 0.1150 - val_loss: 2.3343 - val_accuracy: 0.0850\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 2.3298 - accuracy: 0.1150 - val_loss: 2.3342 - val_accuracy: 0.0850\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3297 - accuracy: 0.1160 - val_loss: 2.3341 - val_accuracy: 0.0850\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3295 - accuracy: 0.1160 - val_loss: 2.3341 - val_accuracy: 0.0850\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3293 - accuracy: 0.1160 - val_loss: 2.3340 - val_accuracy: 0.0850\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3291 - accuracy: 0.1160 - val_loss: 2.3339 - val_accuracy: 0.0850\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3290 - accuracy: 0.1160 - val_loss: 2.3339 - val_accuracy: 0.0850\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3288 - accuracy: 0.1160 - val_loss: 2.3338 - val_accuracy: 0.0850\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3287 - accuracy: 0.1150 - val_loss: 2.3338 - val_accuracy: 0.0850\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3285 - accuracy: 0.1150 - val_loss: 2.3337 - val_accuracy: 0.0850\n"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1.0,\n",
    "    decay_rate=0.5,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# Sample model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dummy data\n",
    "x_train = tf.random.normal((1000, 32))\n",
    "y_train = tf.random.uniform((1000,), maxval=10, dtype=tf.int32)\n",
    "x_val = tf.random.normal((200, 32))\n",
    "y_val = tf.random.uniform((200,), maxval=10, dtype=tf.int32)\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a363871a",
   "metadata": {},
   "source": [
    "Tensorboard we will see in next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9084d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
